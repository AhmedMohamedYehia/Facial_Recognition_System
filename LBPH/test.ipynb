{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "import cv2\n",
    "from skimage.feature import local_binary_pattern\n",
    "import numpy as np\n",
    "# libraries to support custom function for copying.\n",
    "\n",
    "import errno\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy(src, dest):\n",
    "    try:\n",
    "        shutil.copytree(src, dest)\n",
    "    except OSError as e:\n",
    "        # If the error was caused because the source wasn't a directory\n",
    "        if e.errno == errno.ENOTDIR:\n",
    "            shutil.copy(src, dest)\n",
    "        else:\n",
    "            print('Directory not copied. Error: %s' % e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lfw-funneled.tgz', 'pairs.txt', 'pairsDevTest.txt', 'pairsDevTrain.txt']\n",
      "['lfw-funneled.tgz', 'pairs.txt', 'pairsDevTest.txt', 'pairsDevTrain.txt']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "src = 'lfw/'\n",
    "dest = 'lfw_home'\n",
    "copy(src, dest)\n",
    "\n",
    "print(os.listdir(src))\n",
    "print(os.listdir(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "n_samples: 1140\n",
      "n_features: 2914\n",
      "n_classes: 5\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "lfw_dataset = sklearn.datasets.fetch_lfw_people(data_home=\".\", min_faces_per_person=100, download_if_missing=False)\n",
    "\n",
    "n_samples, h, w = lfw_dataset.images.shape\n",
    "# for machine learning we use the 2 data directly (as relative pixel\n",
    "# positions info is ignored by this model)\n",
    "X = lfw_dataset.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_dataset.target\n",
    "target_names = lfw_dataset.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples: %d\" % n_samples)\n",
    "print(\"n_features: %d\" % n_features)\n",
    "print(\"n_classes: %d\" % n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Split into a training set and a test set using a stratified k fold \n",
    "# split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBPHfromScratch:\n",
    "    def __init__(self):\n",
    "        self.R = 1\n",
    "        self.P = 8\n",
    "        self.filter_size = 3\n",
    "        # Anti-clockwise (right -> up + right -> up -> up + left -> left -> down + left -> down -> down + right)\n",
    "        self.filter_lbp = np.array([[2, 1], [2, 0], [1, 0], [0, 0], [0, 1], [0, 2], [1, 2], [2, 2]])\n",
    "\n",
    "    def Compute_LBP(self, img):\n",
    "        # Determine the dimensions of the input image.\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "\n",
    "        if width < self.filter_size or height < self.filter_size:\n",
    "            raise Exception('Too small input image. Should be at least (2*radius+1) x (2*radius+1)')\n",
    "\n",
    "        out_width = width - self.filter_size + 1\n",
    "        out_height = height - self.filter_size + 1\n",
    "\n",
    "        reference_matrix = img[1:1 + out_height, 1:1 + out_width]\n",
    "\n",
    "        out_img = np.zeros((out_height, out_width))\n",
    "\n",
    "        for i in range(0, 8):\n",
    "            step_x, step_y = self.filter_lbp[i]\n",
    "\n",
    "            sliding_matrix = img[step_y:step_y + out_height, step_x:step_x + out_width]\n",
    "\n",
    "            flags = np.greater_equal(sliding_matrix, reference_matrix)\n",
    "\n",
    "            exponent = np.power(2, i)\n",
    "            out_img = out_img + (flags * exponent)\n",
    "\n",
    "        return out_img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram Comparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matcher:\n",
    "    def __init__(self):\n",
    "        self.n_bins = 256\n",
    "        \n",
    "    def kullback_leibler_divergence(self, p, q):\n",
    "        p = np.asarray(p)\n",
    "        q = np.asarray(q)\n",
    "        filt = np.logical_and(p != 0, q != 0)\n",
    "        return np.sum(p[filt] * np.log2(p[filt] / q[filt]))\n",
    "\n",
    "    def match(self, refs, lbp):\n",
    "        best_score = float('inf')\n",
    "        best_name = None\n",
    "        #hist = cv2.calcHist([lbp], [0], None, [256], [0, 256])\n",
    "        #hist /= hist.sum()\n",
    "        hist, _ = np.histogram(lbp, density = True, bins=8 + 2)\n",
    "        for name, ref_hist in refs:\n",
    "            print(hist.shape, ref_hist.shape)\n",
    "            score = self.kullback_leibler_divergence(hist, ref_hist)\n",
    "            #score = cv2.compareHist(hist, ref_hist, cv2.HISTCMP_CHISQR)\n",
    "            if np.abs(score) < best_score:\n",
    "                best_score = np.abs(score)\n",
    "                best_name = name\n",
    "        best_score = best_score * 100\n",
    "        return best_name, best_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbph_2 = LBPHfromScratch()\n",
    "classifier = Matcher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBPH from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_list = []\n",
    "for item_iter, img_name in zip(X_train,y_train):\n",
    "    gray_img = item_iter.reshape((h, w))\n",
    "    temp_img = lbph_2.Compute_LBP(gray_img)\n",
    "    ref_hist = cv2.calcHist([temp_img], [0], None, [256], [0, 256])\n",
    "    ref_hist /= ref_hist.sum()\n",
    "    enc_list.append((img_name, ref_hist))\n",
    "\n",
    "weights_array = np.array(enc_list, dtype=object)\n",
    "\n",
    "with open('weights.npy', 'wb') as f:\n",
    "    np.save(f, weights_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  75.08771929824562\n"
     ]
    }
   ],
   "source": [
    "with open('weights.npy', 'rb') as f:\n",
    "    weights_array = np.load(f, allow_pickle=True)\n",
    "    \n",
    "# Detect Faces\n",
    "err = 0\n",
    "\n",
    "for item_iter, img_name in zip(X_test,y_test):\n",
    "    gray_test_img = item_iter.reshape((h, w))\n",
    "    lbp_img = lbph_2.Compute_LBP(gray_test_img)\n",
    "    \n",
    "    best_score = float('inf')\n",
    "    best_name = None\n",
    "    hist = cv2.calcHist([lbp_img], [0], None, [256], [0, 256])\n",
    "    hist /= hist.sum()\n",
    "    for name, ref_hist in weights_array:\n",
    "        score = cv2.compareHist(hist, ref_hist, cv2.HISTCMP_CORREL)\n",
    "        if np.abs(score) < best_score:\n",
    "            best_score = np.abs(score)\n",
    "            best_name = name\n",
    "            \n",
    "    if best_name!=img_name:\n",
    "        err += 1\n",
    "print(\"Accuracy: \", err * 100 / len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skimage LBPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_list = []\n",
    "for item_iter, img_name in zip(X_train,y_train):\n",
    "    gray_img = item_iter.reshape((h, w))\n",
    "    temp_img = local_binary_pattern(gray_img, 8, 1, 'uniform')\n",
    "    \n",
    "    ref_hist, _ = np.histogram(temp_img, density= True,bins=8 + 2)\n",
    "    enc_list.append((img_name, ref_hist))\n",
    "\n",
    "weights_array = np.array(enc_list, dtype=object)\n",
    "\n",
    "with open('weights.npy', 'wb') as f:\n",
    "    np.save(f, weights_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kullback_leibler_divergence(p, q):\n",
    "        p = np.asarray(p)\n",
    "        q = np.asarray(q)\n",
    "        filt = np.logical_and(p != 0, q != 0)\n",
    "        return np.sum(p[filt] * np.log2(p[filt] / q[filt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  62.45614035087719\n"
     ]
    }
   ],
   "source": [
    "with open('weights.npy', 'rb') as f:\n",
    "    weights_array = np.load(f, allow_pickle=True)\n",
    "    \n",
    "\n",
    "# Detect Faces\n",
    "err = 0\n",
    "\n",
    "for item_iter, img_name in zip(X_test,y_test):\n",
    "    gray_test_img = item_iter.reshape((h, w))\n",
    "    #lbp_img = lbph_2.Compute_LBP(gray_test_img)\n",
    "    lbp_img = local_binary_pattern(gray_test_img, 8, 1, 'uniform')\n",
    "    \n",
    "    best_score = float('inf')\n",
    "    best_name = None\n",
    "    #hist = cv2.calcHist([lbp], [0], None, [256], [0, 256])\n",
    "    #hist /= hist.sum()\n",
    "    hist, _ = np.histogram(lbp_img, density = True, bins=8 + 2)\n",
    "    for name, ref_hist in weights_array:\n",
    "        #print(hist.shape, ref_hist.shape)\n",
    "        score = kullback_leibler_divergence(hist, ref_hist)\n",
    "        #score = cv2.compareHist(hist, ref_hist, cv2.HISTCMP_CHISQR)\n",
    "        if np.abs(score) < best_score:\n",
    "            best_score = np.abs(score)\n",
    "            best_name = name\n",
    "            \n",
    "    #print(n, img_name)\n",
    "    if best_name!=img_name:\n",
    "        err += 1\n",
    "print(\"Accuracy: \", err * 100 / len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78adc1aee7daf3ebc2d56757bb0e282c0ab2812d23514ce46e249ac13e982e61"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('source code': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
