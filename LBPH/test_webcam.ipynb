{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/Maher/opencv_frame_0.png written!\n",
      "images/Maher/opencv_frame_1.png written!\n",
      "images/Maher/opencv_frame_2.png written!\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "name = input(\"Please enter user name: \")\n",
    "\n",
    "os.mkdir(\"images/\" + name)\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"test\")\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"test\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"images/{}/opencv_frame_{}.png\".format(name, img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetectorReady:\n",
    "    def __init__(self):\n",
    "        self.frame_resizing = 1\n",
    "\n",
    "    def detect_borders(self, img):\n",
    "        resized_img = cv2.resize(img, (0, 0), fx=self.frame_resizing, fy=self.frame_resizing)\n",
    "        rgb_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_img)\n",
    "        final_imgs = []\n",
    "        for face_loc in face_locations:\n",
    "            # top, right, bottom, left = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
    "            y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
    "            final_imgs.append(resized_img[y1:y2, x1:x2])\n",
    "\n",
    "        try:\n",
    "            return final_imgs, face_locations\n",
    "        except:\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LBPHfromScratch:\n",
    "    def __init__(self):\n",
    "        self.R = 1\n",
    "        self.P = 8\n",
    "        self.filter_size = 3\n",
    "        # Anti-clockwise (right -> up + right -> up -> up + left -> left -> down + left -> down -> down + right)\n",
    "        self.filter_lbp = np.array([[2, 1], [2, 0], [1, 0], [0, 0], [0, 1], [0, 2], [1, 2], [2, 2]])\n",
    "\n",
    "    def Compute_LBP(self, img):\n",
    "        # Determine the dimensions of the input image.\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "\n",
    "        if width < self.filter_size or height < self.filter_size:\n",
    "            print(\"Size not correct!\")\n",
    "            return\n",
    "\n",
    "        out_width = width - self.filter_size + 1\n",
    "        out_height = height - self.filter_size + 1\n",
    "\n",
    "        reference_matrix = img[1:1 + out_height, 1:1 + out_width]\n",
    "\n",
    "        out_img = np.zeros((out_height, out_width))\n",
    "\n",
    "        for i in range(0, 8):\n",
    "            step_x, step_y = self.filter_lbp[i]\n",
    "\n",
    "            sliding_matrix = img[step_y:step_y + out_height, step_x:step_x + out_width]\n",
    "\n",
    "            flags = np.greater_equal(sliding_matrix, reference_matrix)\n",
    "\n",
    "            exponent = np.power(2, i)\n",
    "            out_img = out_img + (flags * exponent)\n",
    "\n",
    "        return out_img.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matcher:\n",
    "    def __init__(self):\n",
    "        self.n_bins = 256\n",
    "\n",
    "    def match(self, refs, lbp):\n",
    "        best_score = float('inf')\n",
    "        best_name = None\n",
    "        hist = cv2.calcHist([lbp], [0], None, [256], [0, 256])\n",
    "        hist /= hist.sum()\n",
    "\n",
    "        for name, ref_hist in refs:\n",
    "            score = cv2.compareHist(hist, ref_hist, cv2.HISTCMP_CHISQR)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_name = name\n",
    "        best_score = best_score * 100\n",
    "        return best_name, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detect = FaceDetectorReady()\n",
    "lbph_2 = LBPHfromScratch()\n",
    "classifier = Matcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_list = []\n",
    "img_list = []\n",
    "\n",
    "path = 'images'\n",
    "\n",
    "directory_contents = os.listdir(path)\n",
    "for directory in directory_contents:\n",
    "    image_names = os.listdir(path + \"/\" + directory)\n",
    "    for item in image_names:\n",
    "        img_name = directory\n",
    "        img_curr = cv2.imread(path + \"/\" + directory + \"/\" + item)\n",
    "        cropped_img, face_loc_img = face_detect.detect_borders(img_curr)\n",
    "        if cropped_img is None:\n",
    "            continue\n",
    "        for cropped_img_item in cropped_img:\n",
    "            gray_img = cv2.cvtColor(cropped_img_item, cv2.COLOR_RGB2GRAY)\n",
    "            temp_img = lbph_2.Compute_LBP(gray_img)\n",
    "            ref_hist = cv2.calcHist([temp_img], [0], None, [256], [0, 256])\n",
    "            ref_hist /= ref_hist.sum()\n",
    "\n",
    "            # Saving the image\n",
    "            cv2.imwrite(\"mine/\" + img_name + \".jpg\", temp_img)\n",
    "            enc_list.append((img_name, ref_hist))\n",
    "\n",
    "weights_array = np.array(enc_list, dtype=object)\n",
    "\n",
    "with open('weights.npy', 'wb') as f:\n",
    "    np.save(f, weights_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with open('weights.npy', 'rb') as f:\n",
    "    weights_array = np.load(f, allow_pickle=True)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Detect Faces\n",
    "    try:\n",
    "        cropped_test_img, face_loc_test_img = face_detect.detect_borders(frame)\n",
    "\n",
    "        for cropped_img_item, face_loc in zip(cropped_test_img, face_loc_test_img):\n",
    "            gray_test_img = cv2.cvtColor(cropped_img_item, cv2.COLOR_RGB2GRAY)\n",
    "            lbp_img = lbph_2.Compute_LBP(gray_test_img)\n",
    "            n, s = classifier.match(weights_array, lbp_img)\n",
    "\n",
    "            y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
    "\n",
    "            cv2.putText(frame, n + \" \" + str(s), (x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 200), 2)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 200), 4)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    cv2.imshow(\"User\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c1c212813c5f6ea4f4e92bc9b42b27f30e080a3699596269ded603152f1437e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('Deep learning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
