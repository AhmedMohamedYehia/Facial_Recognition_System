{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e503e620",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'commonfunctions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aef1c7ec073e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mFaceAligner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFaceAligner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcommonfunctions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcf\u001b[0m \u001b[1;31m# this a custom module found the commonfunctions.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'commonfunctions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import measure\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "from skimage.morphology import disk, square, dilation, erosion\n",
    "from skimage import data\n",
    "from skimage.feature import Cascade\n",
    "from PupilDetector import GradientIntersect\n",
    "from FaceAligner import FaceAligner\n",
    "import imutils\n",
    "import commonfunctions as cf # this a custom module found the commonfunctions.py\n",
    "from scipy import signal\n",
    "from skimage import filters\n",
    "from skimage import feature\n",
    "import skimage.io as io\n",
    "from scipy import fftpack\n",
    "from scipy.signal import convolve2d\n",
    "from skimage.util import random_noise\n",
    "from skimage.exposure import rescale_intensity\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kEyePercentTop = 25\n",
    "kEyePercentSide = 8\n",
    "kEyePercentHeight = 30\n",
    "kEyePercentWidth = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ce3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropImage(image, p_width, p_hieght):\n",
    "    width = image.shape[0]\n",
    "    height = image.shape[1]\n",
    "    left = int((width - width*p_width)//2)\n",
    "    top = int((height - height*p_hieght)//2)\n",
    "    right = int((width +  width*p_width)//2)\n",
    "    bottom = int((height + height*p_hieght)//2)\n",
    "    \n",
    "    return image[left:right, top:bottom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc2028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEyesCenter(face_BGR):\n",
    "    \n",
    "    gi = GradientIntersect()\n",
    "    img_GRAY = cv2.cvtColor(face_BGR, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    eye_region_width = face_BGR.shape[0] * (kEyePercentWidth/100.0)\n",
    "    eye_region_height = face_BGR.shape[0] * (kEyePercentHeight/100.0)\n",
    "    eye_region_top = face_BGR.shape[1] * (kEyePercentTop/100.0)\n",
    "    \n",
    "    global leftEyeRegion\n",
    "    global rightEyeRegion\n",
    "    leftEyeRegion = (1,1,1,1)\n",
    "    rightEyeRegion = (1,1,1,1)\n",
    "\n",
    "    leftEyeRegion = int(face_BGR.shape[0]*(kEyePercentSide/100.0)), int(eye_region_top), int(eye_region_width), int(eye_region_height)\n",
    "    rightEyeRegion = int(face_BGR.shape[0] - eye_region_width - face_BGR.shape[0]*(kEyePercentSide/100.0)), int(eye_region_top),int(eye_region_width),int(eye_region_height)\n",
    "    \n",
    "    x1, y1, w1, h1 = (leftEyeRegion)\n",
    "    region_left = img_GRAY[int(y1) :int(y1) + int(h1) , int(x1) :int(x1) + int(w1)]\n",
    "    leftEyeCenter = gi.locate(region_left)\n",
    "    \n",
    "    region_left = cv2.circle(region_left, (leftEyeCenter[1], leftEyeCenter[0]), 1, (255,0,255), -1)\n",
    "    cv2.imshow('Left Eye Center', region_left)\n",
    "    \n",
    "    x2, y2, w2, h2 = (rightEyeRegion)\n",
    "    region_right = img_GRAY[int(y2) :int(y2) + int(h2) , int(x2) :int(x2) + int(w2)]\n",
    "    rightEyeCenter = gi.locate(region_right)\n",
    "    \n",
    "    region_right = cv2.circle(region_right, (rightEyeCenter[1], rightEyeCenter[0]), 1, (255,0,255), -1)\n",
    "    cv2.imshow('Right Eye Center', region_right)\n",
    "    \n",
    "    return (int(leftEyeCenter[1])+int(x1) , int(leftEyeCenter[0])+int(y1)), (int(rightEyeCenter[1])+int(x2), int(rightEyeCenter[0])+int(y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686b0ab",
   "metadata": {},
   "source": [
    "# Testing using webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ba9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "webcam = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "gi = GradientIntersect()\n",
    "\n",
    "leftEyeCenter = (0, 0)\n",
    "rightEyeCenter = (0, 0)\n",
    "leftEyeRegionStart = (0, 0)\n",
    "rightEyeRegionStart= (0, 0)\n",
    "face_rect = (0, 0, 0, 0)\n",
    "fa = FaceAligner(desiredFaceWidth=255)\n",
    "while True:\n",
    "    (_, img_BGR) = webcam.read()\n",
    "    \n",
    "    img_GRAY = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img_GRAY)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        continue\n",
    "        \n",
    "    for (x, y, w, h) in faces:\n",
    "        face = img_BGR[y :y + h , x :x + w ]\n",
    "        face = cropImage(face, 0.9, 0.8)\n",
    "        leftEyeCenter, rightEyeCenter = getEyesCenter(face)\n",
    "        face = cv2.circle(face, (leftEyeCenter[0], leftEyeCenter[1]), 1, (255,0,255), -1)\n",
    "        face = cv2.circle(face, (rightEyeCenter[0], rightEyeCenter[1]), 1, (255,0,255), -1)\n",
    "        \n",
    "        imageAligned = fa.align(img_BGR, rightEyeCenter, leftEyeCenter)\n",
    "        detected_faces = face_cascade.detectMultiScale(cv2.cvtColor(imageAligned, cv2.COLOR_BGR2GRAY))\n",
    "        if len(detected_faces) > 0:\n",
    "            \n",
    "            (xA, yA, wA, hA) = detected_faces[0]\n",
    "            faceAligned = imageAligned[yA :yA + hA , xA :xA + wA]\n",
    "            \n",
    "            cv2.imshow('Face before 2D Alignment', face)\n",
    "            \n",
    "            cv2.imshow('Image after 2D Alignment', faceAligned)\n",
    "            cv2.imshow('Face after 2D Alignment', imageAligned)\n",
    "            #cv2.imshow('Image before 2D Alignment', img_BGR)\n",
    "        break\n",
    "    \n",
    "    key = cv2.waitKey(5)    \n",
    "    if key == 27:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "webcam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b014c8a7",
   "metadata": {},
   "source": [
    "# Testin Using Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99575c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the below URL with your own. Make sure to add \"/shot.jpg\" at last.\n",
    "url = \"http://192.168.1.3:8080/shot.jpg\"\n",
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "\n",
    "gi = GradientIntersect()\n",
    "fa = FaceAligner(desiredFaceWidth=255)\n",
    "\n",
    "leftEyeCenter = (0, 0)\n",
    "rightEyeCenter = (0, 0)\n",
    "leftEyeRegionStart = (0, 0)\n",
    "rightEyeRegionStart= (0, 0)\n",
    "face_rect = (0, 0, 0, 0)\n",
    "\n",
    "# While loop to continuously fetching data from the Url\n",
    "while True:\n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    img_BGR = cv2.imdecode(img_arr, -1)\n",
    "    img_BGR = imutils.resize(img_BGR, width=480, height=960)\n",
    "    #cv2.imshow(\"Android_cam\", img)\n",
    "    \n",
    "    \n",
    "    img_GRAY = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img_GRAY)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        continue\n",
    "        \n",
    "    for (x, y, w, h) in faces:\n",
    "        face = img_BGR[y :y + h , x :x + w ]\n",
    "        face = cropImage(face, 0.9, 0.8)\n",
    "        leftEyeCenter, rightEyeCenter = getEyesCenter(face)\n",
    "        face = cv2.circle(face, (leftEyeCenter[0], leftEyeCenter[1]), 1, (255,0,255), -1)\n",
    "        face = cv2.circle(face, (rightEyeCenter[0], rightEyeCenter[1]), 1, (255,0,255), -1)\n",
    "        \n",
    "        imageAligned = fa.align(img_BGR, rightEyeCenter, leftEyeCenter)\n",
    "        detected_faces = face_cascade.detectMultiScale(cv2.cvtColor(imageAligned, cv2.COLOR_BGR2GRAY))\n",
    "        if len(detected_faces) > 0:\n",
    "            \n",
    "            (xA, yA, wA, hA) = detected_faces[0]\n",
    "            faceAligned = imageAligned[yA :yA + hA , xA :xA + wA]\n",
    "            \n",
    "            cv2.imshow('Face before 2D Alignment', face)\n",
    "            \n",
    "            cv2.imshow('Image after 2D Alignment', faceAligned)\n",
    "            cv2.imshow('Face after 2D Alignment', imageAligned)\n",
    "            #cv2.imshow('Image before 2D Alignment', img_BGR)\n",
    "        break\n",
    "        \n",
    "    # Press Esc key to exit\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a227c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
