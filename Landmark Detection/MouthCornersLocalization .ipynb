{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edda258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import measure\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "from skimage.morphology import disk, square, dilation, erosion\n",
    "from skimage import data\n",
    "from skimage.feature import Cascade\n",
    "from EyeCenterLocator import EyeCenterLocator\n",
    "from FaceAligner import FaceAligner\n",
    "import imutils\n",
    "from scipy import signal\n",
    "from skimage import filters\n",
    "from skimage import feature\n",
    "import skimage.io as io\n",
    "from scipy import fftpack\n",
    "from scipy.signal import convolve2d\n",
    "from skimage.util import random_noise\n",
    "from skimage.exposure import rescale_intensity\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822ec2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skinDetection(sourceImage):\n",
    "    min_YCrCb = np.array([0,133,77],np.uint8)\n",
    "    max_YCrCb = np.array([255,173,127],np.uint8)\n",
    "\n",
    "    # Convert image to YCrCb\n",
    "    imageYCrCb = cv2.cvtColor(sourceImage,cv2.COLOR_RGB2YCR_CB)\n",
    "\n",
    "    # Find region with skin tone in YCrCb image\n",
    "    skinRegion = cv2.inRange(imageYCrCb,min_YCrCb,max_YCrCb)\n",
    "\n",
    "    # Do contour detection on skin region\n",
    "    contours, hierarchy = cv2.findContours(skinRegion, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw the contour on the source image\n",
    "    max_contour_area = -1\n",
    "    max_contour_index = -1\n",
    "    for i, c in enumerate(contours):\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > max_contour_area:\n",
    "            max_contour_index = i\n",
    "            max_contour_area = area\n",
    "    sourceImage = np.zeros(sourceImage.shape).astype(sourceImage.dtype)\n",
    "    if max_contour_index > -1: \n",
    "        cv2.drawContours(sourceImage, contours, max_contour_index, (255, 255, 255), -1)\n",
    "    sourceImage = cv2.cvtColor(sourceImage,cv2.COLOR_RGB2GRAY)\n",
    "    return sourceImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da7bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMouthMap(image_RGB):\n",
    "    # transform the image to the YCbCr space\n",
    "    image_YCrCb = cv2.cvtColor(image_RGB, cv2.COLOR_RGB2YCR_CB)\n",
    "    \n",
    "    # extracting YCbCr space components\n",
    "    Y = image_YCrCb[:,:,0]\n",
    "    Cr = np.asarray(image_YCrCb[:,:,1], np.int16)\n",
    "    Cb = np.asarray(image_YCrCb[:,:,2], np.int16)\n",
    "    \n",
    "    skin = skinDetection(image_RGB)\n",
    "    \n",
    "    # calculating the MouthMap\n",
    "    n = np.count_nonzero(skin==255)\n",
    "        \n",
    "    eta = 0\n",
    "    \n",
    "    try:\n",
    "        v_1 = np.power(Cr[skin==255],2)\n",
    "        v_1 =  v_1/(np.amax(v_1)/255.0)\n",
    "\n",
    "        v_2 = np.divide(Cr[skin==255],Cb[skin==255])\n",
    "        v_2 =  v_2/(np.amax(v_2)/255.0)\n",
    "\n",
    "        eta = 0.95 * np.sum(v_1)/np.sum(v_2)\n",
    "    except ValueError:  #raised if `v_1` is empty or `v_2`\n",
    "        pass\n",
    "    \n",
    "    val_1 = np.power(Cr,2)\n",
    "    val_1 = val_1/(np.amax(val_1)/255.0)\n",
    "\n",
    "    val_2 = Cr/Cb\n",
    "    val_2 = val_2/(np.amax(val_2)/255.0)\n",
    "\n",
    "    MouthMap = val_1 * np.power(val_1 - eta * val_2, 2)\n",
    "    MouthMap = MouthMap/(np.amax(MouthMap)/255.0)\n",
    "    \n",
    "    mask = disk(10)\n",
    "    MouthMap = dilation(MouthMap, selem=mask)\n",
    "    \n",
    "    MouthMap = cv2.bitwise_and(MouthMap,  MouthMap,mask =skin)\n",
    "    \n",
    "    MouthMap = np.asarray(MouthMap, dtype='uint8')\n",
    "    \n",
    "    ret2,MouthMap = cv2.threshold(MouthMap,0,1,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return MouthMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096824f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MouthMapROI(image_RGB):\n",
    "    mouth_ROI = face[2*face.shape[0]//3:face.shape[0],face.shape[1]//3:2*face.shape[1]//3]\n",
    "    start_x = w//3\n",
    "    start_y = 2*h//3\n",
    "    mouth = GetMouthMap(mouth_ROI)\n",
    "    contours, hierarchy = cv2.findContours(mouth, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    l = len(contours)\n",
    "    #for contour in contours:\n",
    "    x_c = 0\n",
    "    y_c = 0\n",
    "    w_c = 0\n",
    "    h_c = 0\n",
    "    if len(contours) > 0:\n",
    "        x_c,y_c,w_c,h_c = cv2.boundingRect(contours[-1])\n",
    "        x_c += (start_x)\n",
    "        y_c += (start_y)\n",
    "    return x_c,y_c,w_c,h_c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8f3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "webcam = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "while True:\n",
    "    (_, im) = webcam.read()\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "    l = 0\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = cv2.cvtColor(im[y :y + h , x :x + w ], cv2.COLOR_BGR2RGB)\n",
    "        cv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        x_c,y_c,w_c,h_c  = MouthMapROI(face)\n",
    "        x_c += (x)\n",
    "        y_c += (y)\n",
    "        \n",
    "        im = cv2.circle(im, (x_c, y_c + h_c//2), 2, (255,0,255), -1)\n",
    "        im = cv2.circle(im, (x_c + w_c, y_c + h_c//2), 2, (255,0,255), -1)\n",
    "        \n",
    "        #im = cv2.rectangle(im, (x_c, y_c), (x_c + w_c, y_c + h_c), (255, 255, 0), 2)\n",
    "        break\n",
    "    cv2.imshow('output',im)\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "webcam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c19972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "webcam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32b1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
